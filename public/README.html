<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DenMune: A density-peak clustering algorithm &mdash; DenMune 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Iris Dataset" href="examples/iris_dataset.html" />
    <link rel="prev" title="Welcome to DenMune’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> DenMune
          </a>
              <div class="version">
                0.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">DenMune: A density-peak clustering algorithm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#based-on-the-paper">Based on the paper</a></li>
<li class="toctree-l2"><a class="reference internal" href="#documentation">Documentation:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#watch-it-in-action">Watch it in action</a></li>
<li class="toctree-l2"><a class="reference internal" href="#when-less-means-more">When less means more</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#installation-and-usage">Installation and Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#install-it">Install It:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#import-it">Import It:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#loading-data">Loading data</a></li>
<li class="toctree-l1"><a class="reference internal" href="#algorithm-s-parameters">Algorithm’s Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="#features">Features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-analyzer">The Analyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#noise-detection">Noise Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#validatation">Validatation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#k-nearest-evolution">K-nearest Evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-scalability">The Scalability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-stability">The Stability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reveal-the-propagation">Reveal the propagation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-run-and-test">How to Run and Test</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#interact-with-the-algorithm">Interact with the algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#repo2docker-binder">Repo2Docker Binder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kaggle-workspace">Kaggle workspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="#google-research-colab">Google Research, CoLab</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#how-to-cite">How to cite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#licensing">Licensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task-list">Task List</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples/iris_dataset.html">Iris Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/chameleon_datasets.html">Chameleon Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/2D_shapes_datasets.html">2D Shapes Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/MNIST_dataset.html">MNIST Dataset</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="characteristics/noise_detection.html">Noise Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="characteristics/clustering_propagation.html">Clustering Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="characteristics/clustering_propagation_snapshots.html">Clustering Propagation Snapshots</a></li>
<li class="toctree-l1"><a class="reference internal" href="characteristics/scalability_and_speed.html">Scalability</a></li>
<li class="toctree-l1"><a class="reference internal" href="characteristics/stability_vs_knn.html">Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="characteristics/k_nearest_evolution.html">K-nearest Neighbor Evolution</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="kaggle/validation.html">Validate Your Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="kaggle/training_MNIST.html">Trining MNIST Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="kaggle/Get_97_by_training_MNIST_dataset.html">Become a Kaggler: Get 97% on MNIST Dataset</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DenMune</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>DenMune: A density-peak clustering algorithm</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/README.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="denmune-a-density-peak-clustering-algorithm">
<h1>DenMune: A density-peak clustering algorithm<a class="headerlink" href="#denmune-a-density-peak-clustering-algorithm" title="Permalink to this headline"></a></h1>
<p>DenMune a clustering algorithm that can find clusters of arbitrary size,
shapes and densities in two-dimensions. Higher dimensions are first
reduced to 2-D using the t-sne. The algorithm relies on a single
parameter K (the number of nearest neighbors). The results show the
superiority of the algorithm. Enjoy the simplicity but the power of
DenMune.</p>
<p><a class="reference external" href="https://pypi.org/project/denmune/"><img alt="PyPI Version" src="https://img.shields.io/pypi/v/denmune.svg" /></a> <a class="reference external" href="https://mybinder.org/v2/gh/egy1st/denmune-clustering-algorithm/HEAD"><img alt="Launch notebook examples in Binder" src="https://static.mybinder.org/badge_logo.svg" /></a> <a class="reference external" href="https://denmune.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/denmune/badge/?version=latest" /></a> <a class="reference external" href="#colab"><img alt="Launch notebook examples in Colaboratory, Google Research" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>
<a class="reference external" href="https://www.kaggle.com/egyfirst/denmune-clustering-iris-dataset?scriptVersionId=84775816"><img alt="Launch notebook examples in Kaggle, the workspace where data scientist meet" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a> <a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320303927"><img alt="Elsevier, journal's article publisher" src="https://img.shields.io/badge/elsevier-published-orange" /></a> <a class="reference external" href="https://data.mendeley.com/datasets/b73cw5n43r/4"><img alt="Research datasets at Mendeley" src="https://img.shields.io/badge/mendeley-data-bluegreen" /></a> <a class="reference external" href="https://choosealicense.com/licenses/bsd-3-clause/"><img alt="BSD 3-Clause “New” or “Revised” License&quot;" src="https://img.shields.io/badge/license-BSD-green" /></a> <a class="reference external" href="https://circleci.com/gh/egy1st/denmune-clustering-algorithm/tree/main"><img alt="CircleCI, continuous integration" src="https://circleci.com/gh/egy1st/denmune-clustering-algorithm/tree/main.svg?style=svg" /></a></p>
<section id="based-on-the-paper">
<h2>Based on the paper<a class="headerlink" href="#based-on-the-paper" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 83%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Paper</p></th>
<th class="head"><p>Journal</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mohamed Abbas, Adel El-Zoghabi, Amin Ahoukry</p></td>
<td rowspan="5"><p><a class="reference external" href="https://www.scimagojr.com/journalsearch.php?q=24823&amp;tip=sid&amp;clean=0"><img alt="scimagojr" src="https://www.scimagojr.com/journal_img.php?id=24823" /></a></p></td>
</tr>
<tr class="row-odd"><td><p><em>DenMune: Density peak based clustering using mutual
nearest neighbors</em></p></td>
</tr>
<tr class="row-even"><td><p>In: Journal of Pattern Recognition, Elsevier,</p></td>
</tr>
<tr class="row-odd"><td><p>volume 109, number 107589, January 2021</p></td>
</tr>
<tr class="row-even"><td><p>DOI:
<a class="reference external" href="https://doi.org/10.1016/j.patcog.2020.107589">https://doi.org/10.1016/j.patcog.2020
.107589</a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="documentation">
<h2>Documentation:<a class="headerlink" href="#documentation" title="Permalink to this headline"></a></h2>
<p>Documentation, including tutorials, are available on
<a class="reference external" href="https://denmune.readthedocs.io">https://denmune.readthedocs.io</a></p>
<p><a class="reference external" href="https://denmune.readthedocs.io/en/latest/?badge=latest"><img alt="read the documentation" src="https://img.shields.io/badge/read_the-docs-orange" /></a></p>
</section>
<section id="watch-it-in-action">
<h2>Watch it in action<a class="headerlink" href="#watch-it-in-action" title="Permalink to this headline"></a></h2>
<p>This 30 seconds will tell you how a density-baased algorithm, DenMune
propagates:</p>
<p><a class="reference external" href="https://colab.research.google.com/drive/1o-tP3uvDGjxBOGYkir1lnbr74sZ06e0U?usp=sharing"><img alt="interact with the propagation" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p><img alt="Propagation in DenMune" src="https://raw.githubusercontent.com/egy1st/denmune-clustering-algorithm/main/images/propagation.gif" /></p>
</section>
<section id="when-less-means-more">
<h2>When less means more<a class="headerlink" href="#when-less-means-more" title="Permalink to this headline"></a></h2>
<p>Most calssic clustering algorithms fail in detecting complex where
clusters are of different size, shape, density, and being exist in noisy
data. Recently, a density-based algorithm named DenMune showed great
ability in detecting complex shapes even in noisy data. it can detect
number of clusters automatically, detect both pre-identified-noise and
post-identified-noise automatically and removing them.</p>
<p>It can achieve accuracy reach 100% in most classic pattern problems,
achieve 97% in MNIST dataset. A great advantage of this algorithm is
being single-parameter algorithm. All you need is to set number of
k-nearest neighbor and the algorithm will care about the rest. Being
Non-senstive to changes in k, make it robust and stable.</p>
<p>Keep in mind, the algorithm reduce any N-D dataset to only 2-D dataset
initially, so it is a good benefit of this algorithm is being always to
plot your data and explore it which make this algorithm a good candidate
for data exploration. Finally, the algorithm comes with neat package for
visualizing data, validating it and analyze the whole clustering
process.</p>
</section>
</section>
<section id="installation-and-usage">
<h1>Installation and Usage<a class="headerlink" href="#installation-and-usage" title="Permalink to this headline"></a></h1>
<section id="install-it">
<h2>Install It:<a class="headerlink" href="#install-it" title="Permalink to this headline"></a></h2>
<p>Simply install DenMune clustering algorithm using pip command from the
official Python repository</p>
<p><a class="reference external" href="https://pypi.org/project/denmune/"><img alt="PyPI Version" src="https://img.shields.io/pypi/v/denmune.svg" /></a></p>
<p>From the shell run the command</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install denmune
</pre></div>
</div>
<p>From jupyter notebook cell run the command</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install denmune
</pre></div>
</div>
</section>
<section id="import-it">
<h2>Import It:<a class="headerlink" href="#import-it" title="Permalink to this headline"></a></h2>
<p>Once DenMune is installed, you just need to import it</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">denmune</span> <span class="kn">import</span> <span class="n">DenMune</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that first <code class="docutils literal notranslate"><span class="pre">denmune</span></code> (the package) is in small letters, while <code class="docutils literal notranslate"><span class="pre">DenMune</span></code> (the class itself) has <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">M</span></code> in capital case while other letters are small.</p>
</div>
</section>
</section>
<section id="loading-data">
<h1>Loading data<a class="headerlink" href="#loading-data" title="Permalink to this headline"></a></h1>
<p>There are four possible cases of data:</p>
<ul class="simple">
<li><p>only train data without labels</p></li>
<li><p>only labeld train data</p></li>
<li><p>labeled train data in addition to test data without labels</p></li>
<li><p>labeled train data in addition to labeled test data</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#=============================================</span>
<span class="c1"># First scenario: train data without labels</span>
<span class="c1"># ============================================</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/denmune/chameleon/&#39;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;t7.10k.csv&quot;</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="n">dataset</span>

<span class="c1"># train data without labels</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">knn</span> <span class="o">=</span> <span class="mi">39</span> <span class="c1"># k-nearest neighbor, the only parameter required by the algorithm</span>

<span class="n">dm</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_analyzer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This is an intutive dataset which has no groundtruth provided</p>
<p><img alt="t710" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/t710.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#=============================================</span>
<span class="c1"># Second scenario: train data with labels</span>
<span class="c1"># ============================================</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/denmune/shapes/&#39;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;aggregation.csv&quot;</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="n">dataset</span>

<span class="c1"># train data with labels</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">knn</span> <span class="o">=</span> <span class="mi">6</span> <span class="c1"># k-nearest neighbor, the only parameter required by the algorithm</span>

<span class="n">dm</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">train_truth</span><span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_analyzer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Datset groundtruth</p>
<p><img alt="aggregation groundtruth" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/aggregation_ground.png" /></p>
<p>Datset as detected by DenMune at k=6</p>
<p><img alt="aggregation train" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/aggregation_6.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#=================================================================</span>
<span class="c1"># Third scenario: train data with labels in addition to test data</span>
<span class="c1"># ================================================================</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/denmune/pendigits/&#39;</span>
<span class="n">file_2d</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;pendigits-2d.csv&#39;</span>

<span class="c1"># train data with labels</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;train.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># test data without labels</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;test.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">knn</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># k-nearest neighbor, the only parameter required by the algorithm</span>

<span class="n">dm</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">train_truth</span><span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
             <span class="n">test_data</span><span class="o">=</span> <span class="n">X_test</span><span class="p">,</span>
             <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_analyzer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>dataset groundtruth</p>
<p><img alt="pendigits groundtruth" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/pendigits_ground.png" /></p>
<p>dataset as detected by DenMune at k=50</p>
<p><img alt="pendigits train" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/pendigits_50.png" /></p>
<p>test data as predicted by DenMune on training the dataset at k=50</p>
<p><img alt="pendigits test" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/pendigits_test_50.png" /></p>
</section>
<section id="algorithm-s-parameters">
<h1>Algorithm’s Parameters<a class="headerlink" href="#algorithm-s-parameters" title="Permalink to this headline"></a></h1>
<ol class="arabic simple">
<li><p>Parameters used within the initialization of the DenMune class</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                  <span class="n">train_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">train_truth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_truth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">file_2d</span> <span class="o">=</span><span class="s1">&#39;_temp_2d&#39;</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                  <span class="n">rgn_tsne</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prop_step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                  <span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><p>train_data:</p>
<ul>
<li><p>data used for training the algorithm</p></li>
<li><p>default: None. It should be provided by the use, otherwise an
error will riase.</p></li>
</ul>
</li>
<li><p>train_truth:</p>
<ul>
<li><p>labels of training data</p></li>
<li><p>default: None</p></li>
</ul>
</li>
<li><p>test_data:</p>
<ul>
<li><p>data used for testing the algorithm</p></li>
</ul>
</li>
<li><p>test_truth:</p>
<ul>
<li><p>labels of testing data</p></li>
<li><p>default: None</p></li>
</ul>
</li>
<li><p>k_nearest:</p>
<ul>
<li><p>number of nearest neighbor</p></li>
<li><p>default: 10. It should be provided by the user.</p></li>
</ul>
</li>
<li><p>rgn_tsn:</p>
<ul>
<li><p>when set to True: It will regenerate the reduced 2-D version of
the N-D dataset each time the algorithm run.</p></li>
<li><p>when set to False: It will generate the reduced 2-D version of the
N-D dataset first time only, then will reuse the saved exist file</p></li>
<li><p>default: True</p></li>
</ul>
</li>
<li><p>file_2d: name (include location) of file used save/load the reduced
2-d version</p>
<ul>
<li><p>if empty: the algorithm will create temporary file named
‘_temp_2d’</p></li>
<li><p>default: _temp_2d</p></li>
</ul>
</li>
<li><p>prop_step:</p>
<ul>
<li><p>size of increment used in showing the clustering propagation.</p></li>
<li><p>leave this parameter set to 0, the default value, unless you are
willing intentionally to enter the propagation mode.</p></li>
<li><p>default: 0</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Parameters used within the fit_predict function:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                   <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">show_plots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">show_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">show_analyzer</span><span class="o">=</span><span class="kc">True</span>
                   <span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><p>validate:</p>
<ul>
<li><p>validate data on/off according to five measures integrated with
DenMUne (Accuracy. F1-score, NMI index, AMI index, ARI index)</p></li>
<li><p>default: True</p></li>
</ul>
</li>
<li><p>show_plots:</p>
<ul>
<li><p>show/hide plotting of data</p></li>
<li><p>default: True</p></li>
</ul>
</li>
<li><p>show_noise:</p>
<ul>
<li><p>show/hide noise and outlier</p></li>
<li><p>default: True</p></li>
</ul>
</li>
<li><p>show_analyzer:</p>
<ul>
<li><p>show/hide the analyzer</p></li>
<li><p>default: True</p></li>
</ul>
</li>
</ul>
</section>
<section id="features">
<h1>Features<a class="headerlink" href="#features" title="Permalink to this headline"></a></h1>
<section id="the-analyzer">
<h2>The Analyzer<a class="headerlink" href="#the-analyzer" title="Permalink to this headline"></a></h2>
<p>The algorithm provide an intutive tool called analyzer, once called it
will provide you with in-depth analysis on how your clustering results
perform.</p>
<p><img alt="DenMune Analyzer" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/analyzer.png" /></p>
</section>
<section id="noise-detection">
<h2>Noise Detection<a class="headerlink" href="#noise-detection" title="Permalink to this headline"></a></h2>
<p>DenMune detects noise and outlier automatically, no need to any further
work from your side.</p>
<ul class="simple">
<li><p>It plots pre-identified noise in black</p></li>
<li><p>It plots post-identified noise in light grey</p></li>
</ul>
<p>You can set show_noise parameter to False.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># let us show noise</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># let us show clean data by removing noise</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">)</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>noisy data</p></th>
<th class="head"><p>clean data</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="noisy data" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/noisy_data.png" /></p></td>
<td><p><img alt="clean data" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/clean_data.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="validatation">
<h2>Validatation<a class="headerlink" href="#validatation" title="Permalink to this headline"></a></h2>
<p>You can get your validation results using 3 methods</p>
<ul class="simple">
<li><p>by showing the Analyzer</p></li>
<li><p>extract values from the validity returned list from fit_predict function</p></li>
<li><p>extract values from the Analyzer dictionary</p></li>
</ul>
<p>There are  five validity measures built-in the algorithm, which are:</p>
<ul class="simple">
<li><p>ACC, Accuracy</p></li>
<li><p>F1 score</p></li>
<li><p>NMI index (Normalized Mutual Information)</p></li>
<li><p>AMI index (Adjusted Mutual Information)</p></li>
<li><p>ARI index (Adjusted Rand Index)</p></li>
</ul>
<p><img alt="validation snapshot" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/validation.png" /></p>
</section>
<section id="k-nearest-evolution">
<h2>K-nearest Evolution<a class="headerlink" href="#k-nearest-evolution" title="Permalink to this headline"></a></h2>
<p>The following chart shows the evolution of pre and post identified noise
in correspondence to increase of number of knn. Also, detected number of
clusters is analyzed in the same chart in relation with both types of
identified noise.</p>
<p><img alt="knn evolution chart" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/knn_vs_noise.png" /></p>
</section>
<section id="the-scalability">
<h2>The Scalability<a class="headerlink" href="#the-scalability" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 44%" />
<col style="width: 56%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>data size</p></th>
<th class="head"><p>time</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>data size: 5000</p></td>
<td><p>time: 2.3139 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 10000</p></td>
<td><p>time: 5.8752 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 15000</p></td>
<td><p>time: 12.4535 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 20000</p></td>
<td><p>time: 18.8466 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 25000</p></td>
<td><p>time: 28.992 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 30000</p></td>
<td><p>time: 39.3166 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 35000</p></td>
<td><p>time: 39.4842 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 40000</p></td>
<td><p>time: 63.7649 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 45000</p></td>
<td><p>time: 73.6828 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 50000</p></td>
<td><p>time: 86.9194 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 55000</p></td>
<td><p>time: 90.1077 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 60000</p></td>
<td><p>time: 125.0228 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 65000</p></td>
<td><p>time: 149.1858 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 70000</p></td>
<td><p>time: 177.4184 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 75000</p></td>
<td><p>time: 204.0712 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 80000</p></td>
<td><p>time: 220.502 seconds</p></td>
</tr>
<tr class="row-even"><td><p>data size: 85000</p></td>
<td><p>time: 251.7625 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>data size: 100000</p></td>
<td><p>time: 257.563 seconds</p></td>
</tr>
</tbody>
</table>
<p><img alt="noisy data chart" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/scalability.png" /></p>
</section>
<section id="the-stability">
<h2>The Stability<a class="headerlink" href="#the-stability" title="Permalink to this headline"></a></h2>
<p>The algorithm is only single-parameter, even more it not sensitive to
changes in that parameter, k. You may guess that from the following
chart yourself. This is of greate benfit for you as a data exploration
analyst. You can simply explore the dataset using an arbitrary k. Being
Non-senstive to changes in k, make it robust and stable.</p>
<p><img alt="DenMune Stability chart" src="https://raw.githubusercontent.com/egy1st/images/main/clustering/stability.png" /></p>
</section>
<section id="reveal-the-propagation">
<h2>Reveal the propagation<a class="headerlink" href="#reveal-the-propagation" title="Permalink to this headline"></a></h2>
<p>one of the top performing feature in this algorithm is enabling you to
watch how your clusters propagate to construct the final output
clusters. just use the parameter ‘prop_step’ as in the following
example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;t7.10k&quot;</span> <span class="c1">#</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/denmune/chameleon/&#39;</span>

<span class="c1"># train file</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span><span class="s1">&#39;.csv&#39;</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>


<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>

<span class="c1"># Denmune&#39;s Paramaters</span>
<span class="n">knn</span> <span class="o">=</span> <span class="mi">39</span> <span class="c1"># number of k-nearest neighbor, the only parameter required by the algorithm</span>

<span class="c1"># create list of differnt snapshots of the propagation</span>
<span class="n">snapshots</span> <span class="o">=</span> <span class="n">chain</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">250</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">5500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="k">for</span> <span class="n">snapshot</span> <span class="ow">in</span> <span class="n">snapshots</span><span class="p">:</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;itration&quot;</span><span class="p">,</span> <span class="n">snapshot</span> <span class="p">)</span>
    <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dm</span> <span class="o">=</span> <span class="n">DenMune</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">k_nearest</span><span class="o">=</span><span class="n">knn</span><span class="p">,</span> <span class="n">rgn_tsne</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prop_step</span><span class="o">=</span><span class="n">snapshot</span><span class="p">)</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">validity</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">show_analyzer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="how-to-run-and-test">
<h1>How to Run and Test<a class="headerlink" href="#how-to-run-and-test" title="Permalink to this headline"></a></h1>
<section id="interact-with-the-algorithm">
<h2>Interact with the algorithm<a class="headerlink" href="#interact-with-the-algorithm" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://colab.research.google.com/drive/1EUROd6TRwxW3A_XD3KTxL8miL2ias4Ue?usp=sharing"><img alt="chameleon datasets" src="https://raw.githubusercontent.com/egy1st/denmune-clustering-algorithm/main/images/chameleon_detection.png" /></a></p>
<p>This notebook allows you interact with the algorithm in many asspects:</p>
<ul class="simple">
<li><p>you can choose which dataset to cluster (among 4 chameleon datasets)</p></li>
<li><p>you can decide which number of k-nearest neighbor to use</p></li>
<li><p>show noise on/off; thus you can invesitigate noise detected by the
algorithm</p></li>
<li><p>show analyzer on/off</p></li>
</ul>
</section>
<section id="repo2docker-binder">
<h2>Repo2Docker Binder<a class="headerlink" href="#repo2docker-binder" title="Permalink to this headline"></a></h2>
<p>Launch Examples in Repo2Docker Binder</p>
<blockquote>
<div><p>Simply use our repo2docker offered by mybinder.org, which encapsulate
the algorithm and all required data in one virtual machine instance.
All jupter notebooks examples found in this repository will be also
available to you in action to practice in this respo2docer. Thanks
mybinder.org, you made it possible!</p>
<p><a class="reference external" href="https://mybinder.org/v2/gh/egy1st/denmune-clustering-algorithm/HEAD"><img alt="Launch notebook examples in Binder" src="https://static.mybinder.org/badge_logo.svg" /></a></p>
</div></blockquote>
</section>
<section id="kaggle-workspace">
<h2>Kaggle workspace<a class="headerlink" href="#kaggle-workspace" title="Permalink to this headline"></a></h2>
<p>Launch each Example in Kaggle workspace</p>
<blockquote>
<div><p>If you are a kaggler like me, then Kaggle, the best workspace where
data scientist meet, should fit you to test the algorithm with great
experince.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Dataset</p></th>
<th class="head"><p>Kaggle URL</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>When less means more - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/when-less-means-more"><img alt="When less means more - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Non-groundtruth datasets -
kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/detecting-non-groundtruth-datasets"><img alt="Non-groundtruth datasets" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>2D Shape datasets - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/detection-of-2d-shape-datasets"><img alt="2D Shape datasets - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>MNIST dataset kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/get-97-using-simple-yet-one-parameter-algorithm"><img alt="MNIST dataset - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Iris dataset kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/denmune-clustering-iris-dataset"><img alt="iris dataset - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Training MNIST to get 97%</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/training-mnist-dataset-to-get-97"><img alt="Training MNIST to get 97%" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Noise detection - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/noise-detection"><img alt="Noise detection - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Validation - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/validate-in-5-built-in-validity-insexes"><img alt="Validation - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a> |</p></td>
</tr>
<tr class="row-even"><td><p>The beauty of propagation -
kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/the-beauty-of-clusters-propagation"><img alt="The beauty of propagation - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>The beauty of propagation part2
- kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/the-beauty-of-propagation-part2"><img alt="The beauty of propagation part 2 - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Snapshots of propagation -kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/the-beauty-of-clusters-propagation"><img alt="The beauty of propagation - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Scalability kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/scalability-vs-speed"><img alt="Scalability - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Stability - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/stability-vs-number-of-nearest-neighbor"><img alt="Stability - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>k-nearest-evolution - kaggle</p></td>
<td><p><a class="reference external" href="https://www.kaggle.com/egyfirst/k-nearest-evolution"><img alt="k-nearest-evolution - kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></td>
</tr>
</tbody>
</table>
</div></blockquote>
</section>
<section id="google-research-colab">
<h2>Google Research, CoLab<a class="headerlink" href="#google-research-colab" title="Permalink to this headline"></a></h2>
<p>Launch each Example in Google Research, CoLab</p>
<blockquote>
<div><p>Need to test examples one by one, then here another option. Use colab
offered by google research to test each example individually.</p>
<p class="rubric" id="here-is-a-list-of-google-colab-url-to-use-the-algorithm-interactively">Here is a list of Google CoLab URL to use the algorithm
interactively</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Dataset</p></th>
<th class="head"><p>CoLab URL</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>How to use it - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1J_uKdhZ3z1KeY0-wJ7Ruw2PZSY1orKQm"><img alt="How to use it - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Chameleon datasets - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1EUROd6TRwxW3A_XD3KTxL8miL2ias4Ue?usp=sharing"><img alt="Chameleon datasets - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>2D Shape datasets - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1EaqTPCRHSuTKB-qEbnWHpGKFj6XytMIk?usp=sharing"><img alt="2D Shape datasets - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>MNIST dataset - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1a9FGHRA6IPc5jhLOV46iEbpUeQXptSJp?usp=sharing"><img alt="MNIST dataset - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>iris dataset - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1nKql57Xh7xVVu6NpTbg3vRdRg42R7hjm?usp=sharing"><img alt="iris dataset - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Get 97% by training MNIST
dataset - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1NeOtXEQY94oD98Ufbh3IhTHnnYwIA659"><img alt="Get 97% by training MNIST dataset - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Non-groundtruth datasets - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1d17ejQ83aUy0CZIeQ7bHTugSC9AjJ2mU?usp=sharing"><img alt="Non-groundtruth datasets - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Noise detection - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1Bp3c-cJfjLWxupmrBJ_6Q4-nqIfZcII4"><img alt="Noise detection - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>validation - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/13_EVaQOv_QiNmQiMWJAcFFHPJHGCrQLe"><img alt="Validation - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>How it propagates - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1o-tP3uvDGjxBOGYkir1lnbr74sZ06e0U?usp=sharing"><img alt="How it propagates - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Snapshots of propagation - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1vPXNKa8Rf3TnqDHSD3YSWl3g1iNSqjl2?usp=sharing"><img alt="snapshots of the propagation - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>Scalability - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1d55wkBndLLapO7Yx1ePHhE8mL61j9-TH?usp=sharing"><img alt="Scalability - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-even"><td><p>Stability vs number of nearest
neighbors - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/17VgVRMFBWvkSIH1yA3tMl6UQ7Eu68K2l?usp=sharing"><img alt="Stability vs number of nearest neighbors - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
<tr class="row-odd"><td><p>k-nearest-evolution - colab</p></td>
<td><p><a class="reference external" href="https://colab.research.google.com/drive/1DZ-CQPV3WwJSiaV3-rjwPwmXw4RUh8Qj"><img alt="k-nearest-evolution - colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p></td>
</tr>
</tbody>
</table>
</div></blockquote>
</section>
</section>
<section id="how-to-cite">
<h1>How to cite<a class="headerlink" href="#how-to-cite" title="Permalink to this headline"></a></h1>
<p>If you have used this codebase in a scientific publication and wish to
cite it, please use the <a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320303927">Journal of Pattern Recognition
article</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Mohamed</span> <span class="n">Abbas</span> <span class="n">McInnes</span><span class="p">,</span> <span class="n">Adel</span> <span class="n">El</span><span class="o">-</span><span class="n">Zoghaby</span><span class="p">,</span> <span class="n">Amin</span> <span class="n">Ahoukry</span><span class="p">,</span> <span class="o">*</span><span class="n">DenMune</span><span class="p">:</span> <span class="n">Density</span> <span class="n">peak</span> <span class="n">based</span> <span class="n">clustering</span> <span class="n">using</span> <span class="n">mutual</span> <span class="n">nearest</span> <span class="n">neighbors</span><span class="o">*</span>
<span class="n">In</span><span class="p">:</span> <span class="n">Journal</span> <span class="n">of</span> <span class="n">Pattern</span> <span class="n">Recognition</span><span class="p">,</span> <span class="n">Elsevier</span><span class="p">,</span> <span class="n">volume</span> <span class="mi">109</span><span class="p">,</span> <span class="n">number</span> <span class="mf">107589.</span>
<span class="n">January</span> <span class="mi">2021</span>
</pre></div>
</div>
<div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">ABBAS2021107589</span><span class="p">,</span><span class="w"></span>
<span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{DenMune: Density peak based clustering using mutual nearest neighbors}</span><span class="p">,</span><span class="w"></span>
<span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Pattern Recognition}</span><span class="p">,</span><span class="w"></span>
<span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{109}</span><span class="p">,</span><span class="w"></span>
<span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{107589}</span><span class="p">,</span><span class="w"></span>
<span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2021}</span><span class="p">,</span><span class="w"></span>
<span class="na">issn</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{0031-3203}</span><span class="p">,</span><span class="w"></span>
<span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://doi.org/10.1016/j.patcog.2020.107589}</span><span class="p">,</span><span class="w"></span>
<span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://www.sciencedirect.com/science/article/pii/S0031320320303927}</span><span class="p">,</span><span class="w"></span>
<span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Mohamed Abbas and Adel El-Zoghabi and Amin Shoukry}</span><span class="p">,</span><span class="w"></span>
<span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Clustering, Mutual neighbors, Dimensionality reduction, Arbitrary shapes, Pattern recognition, Nearest neighbors, Density peak}</span><span class="p">,</span><span class="w"></span>
<span class="na">abstract</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Many clustering algorithms fail when clusters are of arbitrary shapes, of varying densities, or the data classes are unbalanced and close to each other, even in two dimensions. A novel clustering algorithm “DenMune” is presented to meet this challenge. It is based on identifying dense regions using mutual nearest neighborhoods of size K, where K is the only parameter required from the user, besides obeying the mutual nearest neighbor consistency principle. The algorithm is stable for a wide range of values of K. Moreover, it is able to automatically detect and remove noise from the clustering process as well as detecting the target clusters. It produces robust results on various low and high dimensional datasets relative to several known state of the art clustering algorithms.}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<section id="licensing">
<h2>Licensing<a class="headerlink" href="#licensing" title="Permalink to this headline"></a></h2>
<p>The DenMune algorithm is 3-clause BSD licensed. Enjoy.</p>
<p><a class="reference external" href="https://choosealicense.com/licenses/bsd-3-clause/"><img alt="BSD 3-Clause “New” or “Revised” License&quot;" src="https://img.shields.io/badge/license-BSD-green" /></a></p>
</section>
<section id="task-list">
<h2>Task List<a class="headerlink" href="#task-list" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>☒ Update Github with the DenMune sourcode</p></li>
<li><p>☒ create repo2docker repository</p></li>
<li><p>☒ Create pip Package</p></li>
<li><p>☒ create CoLab shared examples</p></li>
<li><p>☒ create documentation</p></li>
<li><p>☒ create Kaggle shared examples</p></li>
<li><p>☐ create conda package</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to DenMune’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="examples/iris_dataset.html" class="btn btn-neutral float-right" title="Iris Dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Mohamed Abbas.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>